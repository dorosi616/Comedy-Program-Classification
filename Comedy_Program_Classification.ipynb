{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsTZabeTBVhV"
      },
      "source": [
        "## 0. 환경 설정하기"
      ],
      "id": "EsTZabeTBVhV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 구글 드라이브 연결하기"
      ],
      "metadata": {
        "id": "xB7iJVzd7eHh"
      },
      "id": "xB7iJVzd7eHh"
    },
    {
      "cell_type": "code",
      "source": [
        "# 코랩 사용 시 구글 드라이브 연결\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0yJHSX-HG6zY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61fe5140-59d9-43ae-b553-5e4304e9f23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "id": "0yJHSX-HG6zY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 경로 확인하기\n",
        "- \"WORK_SPACE\" 에 본인 작업 경로 작성 후 실행(구글 드라이브 최상위에 압축해제 시 그대로 실행. 수정 X).<br>"
      ],
      "metadata": {
        "id": "x0gyKH_wt8sH"
      },
      "id": "x0gyKH_wt8sH"
    },
    {
      "cell_type": "code",
      "source": [
        "# ROOT_PATH 확인 \n",
        "import os\n",
        "\n",
        "# 구글 드라이브 내 프로젝트 압축해제된 영역 (구글 드라이브 최상위에 압축해제 시 그대로 실행 수정 X)\n",
        "WORK_SPACE = \"KT_AIVLE\"\n",
        "\n",
        "if os.getcwd() == '/content' :\n",
        "  # 구글 드라이브 사용 시 \n",
        "  ROOT_PATH = \"/content/drive/MyDrive/\"+WORK_SPACE+\"/AIVLE3rd_individual\"\n",
        "else :\n",
        "  ROOT_PATH = os.path.abspath('..')\n",
        "# Train 데이터 셋 경로\n",
        "TRAIN_PATH = ROOT_PATH + \"/train\"\n",
        "# MODEL 저장 경로\n",
        "MODEL_PATH = ROOT_PATH + \"/model\""
      ],
      "metadata": {
        "id": "yjhDnP89VLjW"
      },
      "execution_count": null,
      "outputs": [],
      "id": "yjhDnP89VLjW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r40YBXSQBVhX"
      },
      "source": [
        "### 3) 라이브러리 불러오기"
      ],
      "id": "r40YBXSQBVhX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "S3yEhuItBVhX"
      },
      "outputs": [],
      "source": [
        "# 필요 라이브러리 불러오기.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Embedding\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "id": "S3yEhuItBVhX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) GPU 환경 확인하기\n"
      ],
      "metadata": {
        "id": "VhHC2aku7pVO"
      },
      "id": "VhHC2aku7pVO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1MDovtfBVhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96bcb82-3a02-447d-d69f-e5e12a17f333"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 7320023453197468865\n",
              " xla_global_id: -1]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# GPU 환경 확인하기\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "id": "B1MDovtfBVhY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaDDJVcfBVhZ"
      },
      "source": [
        "---"
      ],
      "id": "yaDDJVcfBVhZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# read video list\n",
        "\n",
        "video_path = ROOT_PATH + '/video'\n",
        "file_list = os.listdir(video_path)\n",
        "# os.makedirs(path)\n",
        "\n",
        "file_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbC12kouL4b7",
        "outputId": "9efe1dbc-5aaf-421f-a2e5-615c400c66b2"
      },
      "id": "WbC12kouL4b7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jung.mp4', 'park.mp4', 'sam.mp4', 'sayuri.mp4']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "for i in file_list:\n",
        "    \n",
        "    video_file =  video_path + '/' + i\n",
        "    \n",
        "    shuttleVideo = cv2.VideoCapture(video_file)\n",
        "    \n",
        "    name = i[:-4]\n",
        "    \n",
        "    path = ROOT_PATH + \"/image/\" + name\n",
        "\n",
        "    print(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AlWx1gSdtgM",
        "outputId": "c0557418-f5b2-4d2f-b877-83d9bb7f4370"
      },
      "id": "3AlWx1gSdtgM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/KT_AIVLE/AIVLE3rd_individual/image/jung\n",
            "/content/drive/MyDrive/KT_AIVLE/AIVLE3rd_individual/image/park\n",
            "/content/drive/MyDrive/KT_AIVLE/AIVLE3rd_individual/image/sam\n",
            "/content/drive/MyDrive/KT_AIVLE/AIVLE3rd_individual/image/sayuri\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4y7h4fvgpIt7",
        "outputId": "1929909d-d64d-4a55-d575-24e64c6d48d3"
      },
      "id": "4y7h4fvgpIt7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/KT_AIVLE/AIVLE3rd_individual/video/sayuri.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "for i in file_list:\n",
        "    \n",
        "    video_file =  video_path + '/' + i\n",
        "    \n",
        "    shuttleVideo = cv2.VideoCapture(video_file)\n",
        "    \n",
        "    name = i[:-4]\n",
        "    \n",
        "    path = ROOT_PATH + \"/image/\" + name\n",
        "    #os.makedirs(path)\n",
        "    \n",
        "    #img_gray_all = []\n",
        "    \n",
        "    c1 = 0\n",
        "    \n",
        "    while(shuttleVideo.isOpened()):\n",
        "    \n",
        "        hasFrame, img_frame = shuttleVideo.read()\n",
        "    \n",
        "    \n",
        "        if not hasFrame:\n",
        "            break\n",
        "             \n",
        "        if (int(shuttleVideo.get(1) % 5 == 0)):\n",
        "                \n",
        "            img_path = path + '/' + '%d.jpg' %c1\n",
        "            cv2.imwrite(img_path, img_frame)\n",
        "        \n",
        "            # 흑백변환\n",
        "            #img = cv2.imread(img_path)\n",
        "            #img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            #cv2.imwrite(img_path, img_gray)\n",
        "            #img_gray_all.append(img_gray)\n",
        "                \n",
        "        \n",
        "            c1 += 1\n",
        "\n",
        "    print('done')\n",
        "    "
      ],
      "metadata": {
        "id": "ctJcC9R9MV7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bec15497-96ff-4394-cd1e-66863f266611"
      },
      "id": "ctJcC9R9MV7k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n",
            "done\n",
            "done\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_file"
      ],
      "metadata": {
        "id": "bZVHvkeB2yhx",
        "outputId": "d7c70040-d62f-4873-92d8-cb8859bdc2c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "bZVHvkeB2yhx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/KT_AIVLE/AIVLE3rd_individual/video/jung'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_file =  video_path + '/jung'\n",
        "    \n",
        "shuttleVideo = cv2.VideoCapture(video_file)\n",
        "\n",
        "while(shuttleVideo.isOpened()):\n",
        "    \n",
        "        hasFrame, img_frame = shuttleVideo.read()\n",
        "    \n",
        "    \n",
        "        if not hasFrame:\n",
        "            break\n",
        "             \n",
        "        if (int(shuttleVideo.get(1) % 5 == 0)):\n",
        "                \n",
        "            img_path = path + '/' + '%d.jpg' %c1\n",
        "            cv2.imwrite(img_path, img_frame)\n",
        "        \n",
        "            # 흑백변환\n",
        "            #img = cv2.imread(img_path)\n",
        "            #img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "            #cv2.imwrite(img_path, img_gray)\n",
        "            #img_gray_all.append(img_gray)\n",
        "                \n",
        "        \n",
        "            c1 += 1"
      ],
      "metadata": {
        "id": "iVsIgz6v2hGm"
      },
      "id": "iVsIgz6v2hGm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynFemIXbBVhZ"
      },
      "source": [
        "# 1. ImageDataGenerator 생성하기\n"
      ],
      "id": "ynFemIXbBVhZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. ImageDataGenerator 생성하기\n",
        "+ 모델 검증을 위해 데이터를 train:validation(8:2)로 분할합니다.\n",
        "+ 모델 성능 개선을 위해 데이터 증식(Data augmentation)이 필요 시 자유롭게 설정"
      ],
      "metadata": {
        "id": "n4_qeqIxvSKY"
      },
      "id": "n4_qeqIxvSKY"
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "        validation_split = 0.2,\n",
        "        #shear_range=0.2,\n",
        "        horizontal_flip=True\n",
        "        #rotation_range=10.,\n",
        "        #width_shift_range=0.2,\n",
        "        #height_shift_range=0.2\n",
        "        )\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# train_genrator 생성\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    batch_size = 16,\n",
        "    subset='training',\n",
        "    target_size=(480, 854),\n",
        "    class_mode='categorical'\n",
        "  \n",
        ")\n",
        "\n",
        "# validation_generator 생성\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    subset='validation',\n",
        "    target_size=(480, 854),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical' \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ac626ObHlo0",
        "outputId": "e72daaea-b9d8-4a66-a421-09897c204613"
      },
      "id": "_ac626ObHlo0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 4 classes.\n",
            "Found 0 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "TdKYiWgHDPq0"
      },
      "id": "TdKYiWgHDPq0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEQXf5oYBVhb"
      },
      "source": [
        "# 2. 모델 구성하기"
      ],
      "id": "LEQXf5oYBVhb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPbu10gwBVhb"
      },
      "source": [
        "2. Inception V3 모델을 설계하기"
      ],
      "id": "NPbu10gwBVhb"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "\n",
        "\n",
        "def get_model(weights='imagenet'):\n",
        "    # create the base pre-trained model\n",
        "    base_model = InceptionV3(weights=weights, include_top=False)\n",
        "\n",
        "    # add a global spatial average pooling layer\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    # let's add a fully-connected layer\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    # and a logistic layer -- let's say we have 5 classes\n",
        "    for _, dirs, _ in os.walk(train_dir):\n",
        "      break\n",
        "    predictions = Dense(len(dirs), activation='softmax')(x)\n",
        "\n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # compile the model (should be done *after* setting layers to non-trainable)\n",
        "    model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def fine_tune_inception_layer(model):\n",
        "    \"\"\"After we fine-tune the dense layers, train deeper.\"\"\"\n",
        "    # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "    # the first 172 layers and unfreeze the rest:\n",
        "    for layer in model.layers[:172]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[172:]:\n",
        "        layer.trainable = True\n",
        "\n",
        "    # we need to recompile the model for these modifications to take effect\n",
        "    # we use SGD with a low learning rate\n",
        "    model.compile(\n",
        "        optimizer=SGD(lr=0.0001, momentum=0.9),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_model(model, nb_epoch, generators, callbacks=[]):\n",
        "    train_generator, validation_generator = generators\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=10,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=1,\n",
        "        epochs=nb_epoch,\n",
        "        callbacks=callbacks)\n",
        "    return model\n",
        "\n",
        "def main(weights_file):\n",
        "\n",
        "    model = get_model()\n",
        "    generators = get_generators()\n",
        "\n",
        "    if weights_file is None:\n",
        "        print(\"Training Top layers.\")\n",
        "        model = train_model(model, 10, generators)\n",
        "    else:\n",
        "        print(\"Loading saved model: %s.\" % weights_file)\n",
        "        model.load_weights(weights_file)\n",
        "\n",
        "    # Get and train the mid layers.\n",
        "    model = fine_tune_inception_layer(model)\n",
        "    model = train_model(model, 20, generators,\n",
        "                        [checkpointer, early_stopper, tensorboard])\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    weights_file = None\n",
        "    main(weights_file)"
      ],
      "metadata": {
        "id": "6XGZplfBwUmx"
      },
      "id": "6XGZplfBwUmx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "resnet = ResNet50(\n",
        "    input_shape = IMAGE_SIZE + [3], # Making the image into 3 Channel, so concating 3.\n",
        "    weights = 'imagenet', # Default weights.\n",
        "    include_top = False   # \n",
        ")\n",
        "x = Flatten() (resnet.output)\n",
        "prediction = Dense(4, activation = 'softmax')(x)\n",
        "\n",
        "model = Model(inputs = resnet.input, outputs = prediction)"
      ],
      "metadata": {
        "id": "bb_5_pOVwYb0"
      },
      "id": "bb_5_pOVwYb0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}